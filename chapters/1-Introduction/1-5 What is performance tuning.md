## What Is Performance Tuning?

Locating a performance bottleneck is only half of engineerâ€™s job. The second half is to fix it properly. Sometimes changing one line in the source code of a program can yield a drastic performance boost. Missing such opportunities can be quite wasteful. Performance analysis and tuning are all about finding and fixing this line.

To take advantage of all computing power of modern CPUs, you need to understand how they work. Or how performance engineers like to say, you need to have "mechanical sympathy". This term was borrowed from the car racing world. It means that a racing driver with a good understanding of how the car works has an edge over its competitors who don't. The same applies to performance engineering. It is not possible to know all the details of how a modern CPU operates, but you need to have a good mental model of it to squeeze the last bit of performance out of it.

This is what I mean by "low-level optimizations". This is a type of optimization that takes into account the details of the underlying hardware capabilities. It is different from "high-level optimizations" that are more about aplication-level logic, algorithms, and data structures. 

In the past, software developers had more mechanical sympathy as they often had to deal with nuances of the hardware implementation. During the PC era, developers usually were programming directly on top of the operating system, with possibly a few libraries in between. As the world moved to the cloud era, the SW stack got deeper and more complex. The top layer of the stack on which most developers are working has moved further away from the HW. Those additional layers abstract away the actual HW, which allows using new types of accelerators for emerging workloads. However, the negative side of such evolution is that developers of modern applications have less affinity to the actual HW on which their SW is running. Nevertheless, as you will see in the book, majority of low-level optimizations can be applied to a wide variety of modern processors.

> "During the post-Moore era, it will become ever more important to make code run fast and, in particular, to tailor it to the hardware on which it runs." [@Leisersoneaam9744]

According to already mentioned paper [@Leisersoneaam9744], at least in the near term, a large portion of performance gains for most applications will originate from the software stack. Broadly speaking, the software stack includes many layers, e.g., firmware, BIOS, OS, libraries, and the source code of an application. But since most of the lower layers are not under our direct control, a major focus will be made on the source code level.

There is a famous quote: "Premature optimization is the root of all evil". But the opposite is often true as well. Postponed performance engineering work may be too late and cause as much evil as premature optimization. For developers working with performance-critical projects, it is crucial to know how underlying HW works. In such industries, it is a fail-from-the-start when a program is being developed without HW focus. ClickHouse DB is an example of a successful software product that was built around a small but very efficient kernel. Performance characteristics of a software must be a first-class-citizen along with correctness and security starting from day 1. Poor performance can kill a product just as easily as security vulnerabilities.

Performance engineering is important and rewarding work, but it may be very time-consuming. In fact, performance optimization is a never-ending game. There will always be something to optimize. Inevitably, the developer will reach the point of diminishing returns at which further improvement comes at a very high engineering cost and likely will not be worth the efforts. Knowing when to stop optimizing is a critical aspect of performance work. 
